import pandas as pd
import numpy as np
import seaborn as sns
import statsmodels
import matplotlib.pyplot as plt
import math
from scipy.stats import chi2_contingency



observations = pd.read_csv('observations.csv')
print(observations.head())



species = pd.read_csv('species_info.csv')
print(species.head())



#Questions to explore
    #What is the distribution of conservation_status for animals?
    #Are certain types of species more likely to be endangered?
    #Are the differences between species and their conservation status significant?
    #Which species were spotted the most at each park?



species.scientific_name.nunique()

species.category.unique()

species.conservation_status.unique()

species.fillna('No Intervention', inplace=True)

species.groupby('conservation_status').scientific_name.nunique().reset_index()



protection_counts = species.groupby('conservation_status')\
    .scientific_name.nunique().reset_index()\
    .sort_values(by='scientific_name')

plt.figure(figsize=(10, 4))
ax = plt.subplot()
plt.bar(range(len(protection_counts)),
        protection_counts.scientific_name.values)
ax.set_xticks(range(len(protection_counts)))
ax.set_xticklabels(protection_counts.conservation_status.values)
plt.ylabel('Number of Species')
plt.title('Conservation Status by Species')
plt.show()

species['is_protected'] = species.conservation_status != 'No Intervention'

category_counts = species.groupby(['category', 'is_protected'])\
                         .scientific_name.nunique().reset_index()

category_counts.head()



category_pivot = category_counts.pivot(columns='is_protected',
                                      index='category',
                                      values='scientific_name')\
                                .reset_index()

category_pivot

category_pivot.columns = ['category', 'not_protected', 'protected']

category_pivot['percent_protected'] = category_pivot.protected / \
                                      (category_pivot.protected + category_pivot.not_protected)

category_pivot



contingency = [[30, 146],
              [75, 413]]

chi2_contingency(contingency)

contingency = [[30, 146],
               [5, 73]]
chi2_contingency(contingency)

observations = pd.read_csv('observations.csv')
observations.head()

species['is_sheep'] = species.common_names.apply(lambda x: 'Sheep' in x)
species.head()

species[species.is_sheep]

sheep_species = species[(species.is_sheep) & (species.category == 'Mammal')]
sheep_species

sheep_observations = observations.merge(sheep_species)
sheep_observations

obs_by_park = sheep_observations.groupby('park_name').observations.sum().reset_index()
obs_by_park

plt.figure(figsize=(16, 4))
ax = plt.subplot()
plt.bar(range(len(obs_by_park)),
        obs_by_park.observations.values)
ax.set_xticks(range(len(obs_by_park)))
ax.set_xticklabels(obs_by_park.park_name.values)
plt.ylabel('Number of Observations')
plt.title('Observations of Sheep per Week')
plt.show()

minimum_detectable_effect = 100 * 0.05 / 0.15
minimum_detectable_effect

baseline = 15

sample_size_per_variant = 870

bryce = 870 / 250.
yellowstone = 810 / 507.

# Approximately 3.5 weeks at Bryce and 1.5 weeks at Yellowstone.
